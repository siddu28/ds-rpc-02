{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281d4466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddu\\Downloads\\ds-rpc-02\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict, Features, Sequence, ClassLabel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366c2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"O\": 0,       # Outside\n",
    "    \"B-ADE\": 1,   # Beginning of an ADE\n",
    "    \"I-ADE\": 2,   # Inside of an ADE\n",
    "    \"B-DRUG\": 3,  # Beginning of a DRUG\n",
    "    \"I-DRUG\": 4   # Inside of a DRUG\n",
    "}\n",
    "id2label = {v: k for k, v in label_map.items()}\n",
    "\n",
    "ner_tags_feature = ClassLabel(names=list(label_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0a7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(filepath, is_weak_data=False):\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    processed_data = {\n",
    "        \"id\": [],\n",
    "        \"tokens\": [],\n",
    "        \"ner_tags\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing {filepath}... Found {len(data)} records.\")\n",
    "\n",
    "    for i, record in enumerate(data):\n",
    "        if is_weak_data:\n",
    "            text = record['data']['text']\n",
    "            annotations = record['annotations'][0]['result']\n",
    "        else: \n",
    "            text = record['data']['SYMPTOM_TEXT'] \n",
    "            annotations = record.get('annotations', [{}])[0].get('result', [])\n",
    "\n",
    "        if not isinstance(text, str):\n",
    "            continue\n",
    "\n",
    "\n",
    "        tokens = text.split()\n",
    "        tags = [label_map[\"O\"]] * len(tokens)\n",
    "        \n",
    "        try:\n",
    "            for ann in annotations:\n",
    "                label_info = ann['value']\n",
    "                label_name = label_info['labels'][0]\n",
    "                start, end = label_info['start'], label_info['end']\n",
    "                \n",
    "                span_text = text[start:end]\n",
    "                span_tokens = span_text.split()\n",
    "                if not span_tokens:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                for i_tok in range(len(tokens) - len(span_tokens) + 1):\n",
    "\n",
    "                    if tokens[i_tok:i_tok+len(span_tokens)] == span_tokens:\n",
    "                        tags[i_tok] = label_map[f\"B-{label_name}\"] # Beginning tag\n",
    "                        for j in range(1, len(span_tokens)):\n",
    "                            tags[i_tok+j] = label_map[f\"I-{label_name}\"] # Inside tag\n",
    "                        break \n",
    "\n",
    "            processed_data[\"id\"].append(i)\n",
    "            processed_data[\"tokens\"].append(tokens)\n",
    "            processed_data[\"ner_tags\"].append(tags)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "\n",
    "    hf_dataset = Dataset.from_dict(processed_data)\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "423aecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\Siddu\\Downloads\\New folder\\ds-rpc-02\\data\\processed\\weak_data.json... Found 80331 records.\n",
      "Processing C:\\Users\\Siddu\\Downloads\\ds-rpc-02\\data\\processed\\annotations_output.json... Found 500 records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 80331/80331 [00:00<00:00, 229276.22 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 400/400 [00:00<00:00, 26358.13 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 55849.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "weak_dataset = load_and_prepare_data(r\"C:\\Users\\Siddu\\Downloads\\New folder\\ds-rpc-02\\data\\processed\\weak_data.json\", is_weak_data=True)\n",
    "\n",
    "gold_dataset = load_and_prepare_data(r\"C:\\Users\\Siddu\\Downloads\\ds-rpc-02\\data\\processed\\annotations_output.json\", is_weak_data=False)\n",
    "\n",
    "\n",
    "gold_dataset_dict = gold_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "weak_dataset.save_to_disk(r\"C:\\Users\\Siddu\\Downloads\\New folder\\ds-rpc-02\\data\\processed\\hf_weak_dataset\")\n",
    "gold_dataset_dict.save_to_disk(r\"C:\\Users\\Siddu\\Downloads\\New folder\\ds-rpc-02\\data\\processed\\hf_gold_dataset_dict\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6d249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
